{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE    FF  INDPRO   CPI    VIX  DGS10\n",
      "0  01-01-2000  5.45    4.80  2.11  23.20   6.66\n",
      "1  01-02-2000  5.73    4.56  2.16  23.60   6.52\n",
      "2  01-03-2000  5.85    4.74  2.45  22.72   6.26\n",
      "3  01-04-2000  6.02    5.17  2.27  27.16   5.99\n",
      "4  01-05-2000  6.27    4.84  2.38  26.37   6.44\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\vinee\\OneDrive\\Desktop\\projects\\BondYeild_Prediction\\newfredgraph.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296 entries, 0 to 295\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   DATE    296 non-null    object \n",
      " 1   FF      296 non-null    float64\n",
      " 2   INDPRO  296 non-null    float64\n",
      " 3   CPI     296 non-null    float64\n",
      " 4   VIX     296 non-null    float64\n",
      " 5   DGS10   296 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 14.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               FF      INDPRO         CPI         VIX       DGS10\n",
      "count  296.000000  296.000000  296.000000  296.000000  296.000000\n",
      "mean     1.881081    0.681655    2.378851   19.905541    3.272027\n",
      "std      2.008133    4.405529    1.142222    8.118895    1.306952\n",
      "min      0.050000  -17.200000    0.600000   10.130000    0.620000\n",
      "25%      0.140000   -1.062500    1.740000   14.077500    2.197500\n",
      "50%      1.160000    1.900000    2.140000   17.820000    3.290000\n",
      "75%      3.072500    3.090000    2.482500   23.457500    4.262500\n",
      "max      6.540000   16.120000    6.640000   62.670000    6.660000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              FF    INDPRO       CPI       VIX     DGS10\n",
      "FF      1.000000  0.134926  0.347424 -0.139731  0.752793\n",
      "INDPRO  0.134926  1.000000  0.143670 -0.434660  0.148817\n",
      "CPI     0.347424  0.143670  1.000000  0.026629  0.085390\n",
      "VIX    -0.139731 -0.434660  0.026629  1.000000 -0.004733\n",
      "DGS10   0.752793  0.148817  0.085390 -0.004733  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = data.drop(columns= ['DATE']).corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vinee\\onedrive\\desktop\\projects\\bondyeild_prediction\\myenv\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 26.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 30.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 22.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 7.6/44.5 MB 35.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.2/44.5 MB 33.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 23.6/44.5 MB 37.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.7/44.5 MB 37.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 37.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 32.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE        FF    INDPRO       CPI       VIX  DGS10\n",
      "0 2000-01-01  0.832049  0.660264  0.250000  0.248763   6.66\n",
      "1 2000-02-01  0.875193  0.653061  0.258278  0.256376   6.52\n",
      "2 2000-03-01  0.893683  0.658463  0.306291  0.239627   6.26\n",
      "3 2000-04-01  0.919877  0.671369  0.276490  0.324134   5.99\n",
      "4 2000-05-01  0.958398  0.661465  0.294702  0.309098   6.44\n"
     ]
    }
   ],
   "source": [
    "#normalizing the input variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%d-%m-%Y')\n",
    "\n",
    "X= data[['FF','INDPRO','CPI','VIX']]\n",
    "Y= data[['DGS10']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Keeping the column names, converting back to dataframe\n",
    "X_scaled_DF = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "#combining the data\n",
    "N_data = pd.concat([data['DATE'], X_scaled_DF,Y], axis =1)\n",
    "\n",
    "print(N_data.head())\n",
    "\n",
    "N_data.to_csv('normalized_bonddata.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296 entries, 0 to 295\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   DATE    296 non-null    datetime64[ns]\n",
      " 1   FF      296 non-null    float64       \n",
      " 2   INDPRO  296 non-null    float64       \n",
      " 3   CPI     296 non-null    float64       \n",
      " 4   VIX     296 non-null    float64       \n",
      " 5   DGS10   296 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 14.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(N_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\vinee\\onedrive\\desktop\\projects\\bondyeild_prediction\\myenv\\lib\\site-packages (24.3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tesnorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\vinee\\OneDrive\\Desktop\\projects\\BondYeild_Prediction\\normalized_bonddata.csv')\n",
    "\n",
    "#splitting the data into training(2000-2020) and testing (2020-2024)\n",
    "train_data = data[(data['DATE']>= '2000-01-01') & (data['DATE'] <= '2020-12-31')]\n",
    "test_data = data[(data['DATE']>= '2020-01-01') & (data['DATE'] <= '2024-12-31')]\n",
    "\n",
    "# seperating features and target\n",
    "X_train = train_data[['FF','CPI','INDPRO','VIX']]\n",
    "Y_train = train_data['DGS10']\n",
    "\n",
    "X_test = test_data[['FF','CPI','INDPRO','VIX']]\n",
    "Y_test = test_data['DGS10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#input layer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#second layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "#third layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0001), loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "#Predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "#comparing the yields\n",
    "comparison = pd.DataFrame({'Date': test_data['DATE'], 'Actual': Y_test,'Predicted':Y_pred.flatten()})\n",
    "print(comparison)\n",
    "\n",
    "#evaluating the model\n",
    "loss = model.evaluate(X_test, Y_test)\n",
    "print(f'Mean Squared Error on the test set: {loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
