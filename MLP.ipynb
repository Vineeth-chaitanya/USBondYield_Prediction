{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE    FF  INDPRO   CPI    VIX  DGS10\n",
      "0  01-01-2000  5.45    4.80  2.11  23.20   6.66\n",
      "1  01-02-2000  5.73    4.56  2.16  23.60   6.52\n",
      "2  01-03-2000  5.85    4.74  2.45  22.72   6.26\n",
      "3  01-04-2000  6.02    5.17  2.27  27.16   5.99\n",
      "4  01-05-2000  6.27    4.84  2.38  26.37   6.44\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\vinee\\OneDrive\\Desktop\\projects\\BondYeild_Prediction\\newfredgraph.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296 entries, 0 to 295\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   DATE    296 non-null    object \n",
      " 1   FF      296 non-null    float64\n",
      " 2   INDPRO  296 non-null    float64\n",
      " 3   CPI     296 non-null    float64\n",
      " 4   VIX     296 non-null    float64\n",
      " 5   DGS10   296 non-null    float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 14.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               FF      INDPRO         CPI         VIX       DGS10\n",
      "count  296.000000  296.000000  296.000000  296.000000  296.000000\n",
      "mean     1.881081    0.681655    2.378851   19.905541    3.272027\n",
      "std      2.008133    4.405529    1.142222    8.118895    1.306952\n",
      "min      0.050000  -17.200000    0.600000   10.130000    0.620000\n",
      "25%      0.140000   -1.062500    1.740000   14.077500    2.197500\n",
      "50%      1.160000    1.900000    2.140000   17.820000    3.290000\n",
      "75%      3.072500    3.090000    2.482500   23.457500    4.262500\n",
      "max      6.540000   16.120000    6.640000   62.670000    6.660000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              FF    INDPRO       CPI       VIX     DGS10\n",
      "FF      1.000000  0.134926  0.347424 -0.139731  0.752793\n",
      "INDPRO  0.134926  1.000000  0.143670 -0.434660  0.148817\n",
      "CPI     0.347424  0.143670  1.000000  0.026629  0.085390\n",
      "VIX    -0.139731 -0.434660  0.026629  1.000000 -0.004733\n",
      "DGS10   0.752793  0.148817  0.085390 -0.004733  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = data.drop(columns= ['DATE']).corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE        FF    INDPRO       CPI       VIX  DGS10\n",
      "0 2000-01-01  0.832049  0.660264  0.250000  0.248763   6.66\n",
      "1 2000-02-01  0.875193  0.653061  0.258278  0.256376   6.52\n",
      "2 2000-03-01  0.893683  0.658463  0.306291  0.239627   6.26\n",
      "3 2000-04-01  0.919877  0.671369  0.276490  0.324134   5.99\n",
      "4 2000-05-01  0.958398  0.661465  0.294702  0.309098   6.44\n"
     ]
    }
   ],
   "source": [
    "#normalizing the input variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%d-%m-%Y')\n",
    "\n",
    "X= data[['FF','INDPRO','CPI','VIX']]\n",
    "Y= data[['DGS10']]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Keeping the column names, converting back to dataframe\n",
    "X_scaled_DF = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "#combining the data\n",
    "N_data = pd.concat([data['DATE'], X_scaled_DF,Y], axis =1)\n",
    "\n",
    "print(N_data.head())\n",
    "\n",
    "N_data.to_csv('normalized_bonddata.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296 entries, 0 to 295\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   DATE    296 non-null    datetime64[ns]\n",
      " 1   FF      296 non-null    float64       \n",
      " 2   INDPRO  296 non-null    float64       \n",
      " 3   CPI     296 non-null    float64       \n",
      " 4   VIX     296 non-null    float64       \n",
      " 5   DGS10   296 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 14.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(N_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (24.3.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vinee\\onedrive\\desktop\\projects\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\vinee\\OneDrive\\Desktop\\projects\\BondYeild_Prediction\\normalized_bonddata.csv')\n",
    "\n",
    "#splitting the data into training(2000-2020) and testing (2020-2024)\n",
    "train_data = data[(data['DATE']>= '2000-01-01') & (data['DATE'] <= '2020-12-31')]\n",
    "test_data = data[(data['DATE']>= '2020-01-01') & (data['DATE'] <= '2024-12-31')]\n",
    "\n",
    "# seperating features and target\n",
    "X_train = train_data[['FF','CPI','INDPRO','VIX']]\n",
    "Y_train = train_data['DGS10']\n",
    "\n",
    "X_test = test_data[['FF','CPI','INDPRO','VIX']]\n",
    "Y_test = test_data['DGS10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vinee\\OneDrive\\Desktop\\projects\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 15.5403 - val_loss: 4.9409\n",
      "Epoch 2/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14.7085 - val_loss: 4.9079\n",
      "Epoch 3/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 15.0075 - val_loss: 4.8752\n",
      "Epoch 4/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.5481 - val_loss: 4.8427\n",
      "Epoch 5/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.5167 - val_loss: 4.8099\n",
      "Epoch 6/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.5945 - val_loss: 4.7751\n",
      "Epoch 7/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.5145 - val_loss: 4.7391\n",
      "Epoch 8/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 14.4142 - val_loss: 4.7023\n",
      "Epoch 9/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 14.4109 - val_loss: 4.6642\n",
      "Epoch 10/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 14.6204 - val_loss: 4.6249\n",
      "Epoch 11/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.8187 - val_loss: 4.5845\n",
      "Epoch 12/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 13.7455 - val_loss: 4.5428\n",
      "Epoch 13/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 14.0259 - val_loss: 4.4986\n",
      "Epoch 14/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14.2212 - val_loss: 4.4528\n",
      "Epoch 15/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 13.6026 - val_loss: 4.4053\n",
      "Epoch 16/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 13.5136 - val_loss: 4.3553\n",
      "Epoch 17/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 13.9781 - val_loss: 4.3039\n",
      "Epoch 18/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 13.7047 - val_loss: 4.2530\n",
      "Epoch 19/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.6032 - val_loss: 4.2033\n",
      "Epoch 20/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.7507 - val_loss: 4.1543\n",
      "Epoch 21/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13.3076 - val_loss: 4.1064\n",
      "Epoch 22/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 13.4180 - val_loss: 4.0597\n",
      "Epoch 23/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 12.9235 - val_loss: 4.0139\n",
      "Epoch 24/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 13.3543 - val_loss: 3.9682\n",
      "Epoch 25/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 12.8283 - val_loss: 3.9228\n",
      "Epoch 26/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 12.6034 - val_loss: 3.8767\n",
      "Epoch 27/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12.3474 - val_loss: 3.8303\n",
      "Epoch 28/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.8670 - val_loss: 3.7829\n",
      "Epoch 29/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.2743 - val_loss: 3.7345\n",
      "Epoch 30/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.1406 - val_loss: 3.6854\n",
      "Epoch 31/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.3043 - val_loss: 3.6343\n",
      "Epoch 32/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.9276 - val_loss: 3.5824\n",
      "Epoch 33/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.8026 - val_loss: 3.5302\n",
      "Epoch 34/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.8789 - val_loss: 3.4779\n",
      "Epoch 35/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 11.5819 - val_loss: 3.4252\n",
      "Epoch 36/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11.5633 - val_loss: 3.3730\n",
      "Epoch 37/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.3599 - val_loss: 3.3205\n",
      "Epoch 38/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 11.5437 - val_loss: 3.2677\n",
      "Epoch 39/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 11.2882 - val_loss: 3.2144\n",
      "Epoch 40/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10.9377 - val_loss: 3.1612\n",
      "Epoch 41/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.7810 - val_loss: 3.1083\n",
      "Epoch 42/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.4491 - val_loss: 3.0551\n",
      "Epoch 43/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.8377 - val_loss: 3.0007\n",
      "Epoch 44/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10.7566 - val_loss: 2.9463\n",
      "Epoch 45/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.5583 - val_loss: 2.8922\n",
      "Epoch 46/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10.4879 - val_loss: 2.8374\n",
      "Epoch 47/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.6187 - val_loss: 2.7817\n",
      "Epoch 48/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 10.0348 - val_loss: 2.7264\n",
      "Epoch 49/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 10.0567 - val_loss: 2.6702\n",
      "Epoch 50/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.6451 - val_loss: 2.6135\n",
      "Epoch 51/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.7090 - val_loss: 2.5562\n",
      "Epoch 52/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2436 - val_loss: 2.4989\n",
      "Epoch 53/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.8945 - val_loss: 2.4411\n",
      "Epoch 54/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.2380 - val_loss: 2.3828\n",
      "Epoch 55/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4955 - val_loss: 2.3239\n",
      "Epoch 56/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.9521 - val_loss: 2.2646\n",
      "Epoch 57/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.8861 - val_loss: 2.2038\n",
      "Epoch 58/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.0593 - val_loss: 2.1426\n",
      "Epoch 59/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2970 - val_loss: 2.0817\n",
      "Epoch 60/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.3749 - val_loss: 2.0206\n",
      "Epoch 61/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.1534 - val_loss: 1.9599\n",
      "Epoch 62/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.0912 - val_loss: 1.8999\n",
      "Epoch 63/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.8877 - val_loss: 1.8399\n",
      "Epoch 64/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7710 - val_loss: 1.7810\n",
      "Epoch 65/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.8397 - val_loss: 1.7226\n",
      "Epoch 66/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.4001 - val_loss: 1.6655\n",
      "Epoch 67/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.3887 - val_loss: 1.6086\n",
      "Epoch 68/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2934 - val_loss: 1.5527\n",
      "Epoch 69/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8405 - val_loss: 1.4974\n",
      "Epoch 70/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8317 - val_loss: 1.4432\n",
      "Epoch 71/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.0288 - val_loss: 1.3899\n",
      "Epoch 72/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.3692 - val_loss: 1.3385\n",
      "Epoch 73/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.2976 - val_loss: 1.2884\n",
      "Epoch 74/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3759 - val_loss: 1.2398\n",
      "Epoch 75/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.0277 - val_loss: 1.1931\n",
      "Epoch 76/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.2153 - val_loss: 1.1475\n",
      "Epoch 77/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.9396 - val_loss: 1.1026\n",
      "Epoch 78/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.6888 - val_loss: 1.0586\n",
      "Epoch 79/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.8476 - val_loss: 1.0158\n",
      "Epoch 80/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.5810 - val_loss: 0.9755\n",
      "Epoch 81/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.3410 - val_loss: 0.9371\n",
      "Epoch 82/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.2818 - val_loss: 0.9001\n",
      "Epoch 83/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.9679 - val_loss: 0.8650\n",
      "Epoch 84/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.0341 - val_loss: 0.8318\n",
      "Epoch 85/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5170 - val_loss: 0.8004\n",
      "Epoch 86/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5034 - val_loss: 0.7704\n",
      "Epoch 87/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3908 - val_loss: 0.7429\n",
      "Epoch 88/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3838 - val_loss: 0.7177\n",
      "Epoch 89/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3449 - val_loss: 0.6948\n",
      "Epoch 90/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0085 - val_loss: 0.6743\n",
      "Epoch 91/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9102 - val_loss: 0.6562\n",
      "Epoch 92/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.7498 - val_loss: 0.6401\n",
      "Epoch 93/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5998 - val_loss: 0.6260\n",
      "Epoch 94/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.3591 - val_loss: 0.6143\n",
      "Epoch 95/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3847 - val_loss: 0.6051\n",
      "Epoch 96/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1981 - val_loss: 0.5985\n",
      "Epoch 97/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0248 - val_loss: 0.5941\n",
      "Epoch 98/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.9874 - val_loss: 0.5919\n",
      "Epoch 99/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8594 - val_loss: 0.5924\n",
      "Epoch 100/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8021 - val_loss: 0.5957\n",
      "Epoch 101/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.7187 - val_loss: 0.6018\n",
      "Epoch 102/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5832 - val_loss: 0.6101\n",
      "Epoch 103/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4661 - val_loss: 0.6211\n",
      "Epoch 104/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2673 - val_loss: 0.6343\n",
      "Epoch 105/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2548 - val_loss: 0.6500\n",
      "Epoch 106/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1208 - val_loss: 0.6679\n",
      "Epoch 107/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1305 - val_loss: 0.6883\n",
      "Epoch 108/250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0284 - val_loss: 0.7099\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "           Date  Actual  Predicted\n",
      "240  2020-01-01    1.76   1.989161\n",
      "241  2020-02-01    1.50   2.179144\n",
      "242  2020-03-01    0.87   3.172011\n",
      "243  2020-04-01    0.66   2.228589\n",
      "244  2020-05-01    0.67   1.843973\n",
      "245  2020-06-01    0.73   1.929910\n",
      "246  2020-07-01    0.62   1.922973\n",
      "247  2020-08-01    0.65   1.827736\n",
      "248  2020-09-01    0.68   1.987504\n",
      "249  2020-10-01    0.79   2.056744\n",
      "250  2020-11-01    0.87   1.913081\n",
      "251  2020-12-01    0.93   1.845419\n",
      "252  2021-01-01    1.08   1.909175\n",
      "253  2021-02-01    1.26   1.761862\n",
      "254  2021-03-01    1.61   1.935448\n",
      "255  2021-04-01    1.64   2.648492\n",
      "256  2021-05-01    1.62   2.804404\n",
      "257  2021-06-01    1.52   2.684446\n",
      "258  2021-07-01    1.32   2.554713\n",
      "259  2021-08-01    1.28   2.463454\n",
      "260  2021-09-01    1.37   2.506180\n",
      "261  2021-10-01    1.58   2.600012\n",
      "262  2021-11-01    1.56   2.714514\n",
      "263  2021-12-01    1.47   2.859726\n",
      "264  2022-01-01    1.76   3.006952\n",
      "265  2022-02-01    1.93   3.288143\n",
      "266  2022-03-01    2.13   3.272056\n",
      "267  2022-04-01    2.75   3.156295\n",
      "268  2022-05-01    2.90   3.270296\n",
      "269  2022-06-01    3.14   3.249383\n",
      "270  2022-07-01    2.90   3.216536\n",
      "271  2022-08-01    2.90   3.311852\n",
      "272  2022-09-01    3.52   3.585304\n",
      "273  2022-10-01    3.98   3.607203\n",
      "274  2022-11-01    3.89   3.419838\n",
      "275  2022-12-01    3.62   3.329953\n",
      "276  2023-01-01    3.53   3.311419\n",
      "277  2023-02-01    3.75   3.315272\n",
      "278  2023-03-01    3.66   3.358383\n",
      "279  2023-04-01    3.46   3.279823\n",
      "280  2023-05-01    3.57   3.258635\n",
      "281  2023-06-01    3.75   3.069808\n",
      "282  2023-07-01    3.90   3.059120\n",
      "283  2023-08-01    4.17   3.071494\n",
      "284  2023-09-01    4.38   2.995967\n",
      "285  2023-10-01    4.80   3.035275\n",
      "286  2023-11-01    4.50   2.946214\n",
      "287  2023-12-01    4.02   2.922639\n",
      "288  2024-01-01    4.06   2.873387\n",
      "289  2024-02-01    4.21   2.895342\n",
      "290  2024-03-01    4.21   2.893435\n",
      "291  2024-04-01    4.54   2.894852\n",
      "292  2024-05-01    4.48   2.810613\n",
      "293  2024-06-01    4.31   2.791957\n",
      "294  2024-07-01    4.25   2.771300\n",
      "295  2024-08-01    3.87   2.911437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1790\n",
      "Mean Squared Error on the test set: 1.174092411994934\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#input layer\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "#second layer\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "#third layer\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0001), loss='mean_squared_error')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, Y_train, epochs=250, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "#Predictions\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "#comparing the yields\n",
    "comparison = pd.DataFrame({'Date': test_data['DATE'], 'Actual': Y_test,'Predicted':Y_pred.flatten()})\n",
    "print(comparison)\n",
    "\n",
    "#evaluating the model\n",
    "loss = model.evaluate(X_test, Y_test)\n",
    "print(f'Mean Squared Error on the test set: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
